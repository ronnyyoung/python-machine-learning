{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 进程与线程\n",
    "\n",
    "Unix/Linux操作系统提供了一个`fork()`系统调用，它非常特殊。普通的函数调用，调用一次，返回一次，但是`fork()`调用一次，返回两次，因为操作系统自动把当前进程（称为父进程）复制了一份（称为子进程），然后，分别在父进程和子进程内返回。\n",
    "\n",
    "子进程永远返回`0`，而父进程返回子进程的ID。这样做的理由是，一个父进程可以`fork`出很多子进程，所以，父进程要记下每个子进程的ID，而子进程只需要调用`getppid()`就可以拿到父进程的ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process (8954) start...\n",
      "I (8954) just created a child process (10255)\n",
      "I am child process (10255) and my parent is 8954\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print('Process (%s) start...' % os.getpid())\n",
    "pid = os.fork()\n",
    "if pid == 0:\n",
    "    print('I am child process (%s) and my parent is %s' % (os.getpid(), os.getppid()))\n",
    "else:\n",
    "    print('I (%s) just created a child process (%s)' % (os.getpid(), pid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Windows下面是没有`fork`调用的。但由于Python是跨平台的，自然应该提供一个跨平台的多进程支持。`multiporcessing`模块就是跨平台的多进程模块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent process 8954.\n",
      "Child process will start.\n",
      "Run child process: test (11403)...\n",
      "Child process end.\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process\n",
    "import os\n",
    "\n",
    "def run_proc(name):\n",
    "    print('Run child process: %s (%s)...' % (name, os.getpid()))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('Parent process %s.' % os.getpid())\n",
    "    p = Process(target=run_proc, args=('test',))\n",
    "    print('Child process will start.')\n",
    "    p.start()\n",
    "    p.join()\n",
    "    print('Child process end.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建子进程时，只需要传入一个执行函数和函数的参数，创建一个Process实例，用start()方法启动，这样创建进程比fork()还要简单。\n",
    "\n",
    "join()方法可以等待子进程结束后再继续往下运行，通常用于进程间的同步。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pool\n",
    "\n",
    "如果要启动大量的子进程，可以用进程池的方式批量创建子进程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent process 8954.\n",
      "Run task 1(14229)\n",
      "Run task 0(14227)\n",
      "Run task 2(14228)\n",
      "Run task 3(14230)\n",
      "Waiting for all subprocess done...\n",
      "Task 3 runs 0.26 seconds.\n",
      "Run task 4(14230)\n",
      "Task 4 runs 0.02 seconds.\n",
      "Task 1 runs 1.40 seconds.\n",
      "Task 0 runs 2.24 seconds.\n",
      "Task 2 runs 2.80 seconds.\n",
      "All subprocesses done.\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "import os, time, random\n",
    "\n",
    "def long_time_task(task_name):\n",
    "    print('Run task %s(%s)' % (task_name, os.getpid()))\n",
    "    start = time.time()\n",
    "    time.sleep(random.random() * 3)\n",
    "    end = time.time()\n",
    "    print('Task %s runs %0.2f seconds.' % (task_name, end-start))\n",
    "if __name__ == '__main__':\n",
    "    print('Parent process %s.' % os.getpid())\n",
    "    # Pool的默认大小等于CPU的核心数\n",
    "    p = Pool(4)\n",
    "    # 这里异步启动的进程数比pool的数量大1，所以最后一个子进程是在前面\n",
    "    # ４个进程中其中之一退出后才开始执行的\n",
    "    for i in range(5):\n",
    "        p.apply_async(long_time_task, args=(i,))\n",
    "    print('Waiting for all subprocess done...')\n",
    "    p.close()\n",
    "    p.join()\n",
    "    print('All subprocesses done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 子进程\n",
    "\n",
    "很多时候，子进程并不是自身，而是一个外部进程。我们创建了子进程后，还需要控制子进程的输入和输出。\n",
    "\n",
    "`subprocess`模块可以让我们非常方便地启动一个子进程，然后控制其输入和输出。\n",
    "\n",
    "下面的例子演示了如何在Python代码中运行命令`nslookup www.python.org`，这和命令行直接运行的效果是一样的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ nslookup www.python.org\n",
      "Exit code: 0\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "print('$ nslookup www.python.org')\n",
    "ret = subprocess.call(['nslookup', 'www.python.org'])\n",
    "print('Exit code:', ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果子进程还需要输入，则可以通过`communicate()`方法输入："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ nslookup\n",
      "Server:\t\t127.0.1.1\n",
      "Address:\t127.0.1.1#53\n",
      "\n",
      "Non-authoritative answer:\n",
      "python.org\tmail exchanger = 50 mail.python.org.\n",
      "\n",
      "Authoritative answers can be found from:\n",
      "mail.python.org\tinternet address = 188.166.95.178\n",
      "\n",
      "\n",
      "Exit code: 0\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "print('$ nslookup')\n",
    "p = subprocess.Popen(['nslookup'], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "output, err = p.communicate(b'set q=mx\\npython.org\\nexit\\n')\n",
    "print(output.decode('utf-8'))\n",
    "print('Exit code:', p.returncode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进程间通信\n",
    "\n",
    "`Process`之间肯定是需要通信的，操作系统提供了很多机制来实现进程间的通信。Python的`multiprocessing`模块包装了底层的机制，提供了`Queue`、`Pipes`等多种方式来交换数据。\n",
    "\n",
    "我们以`Queue`为例，在父进程中创建两个子进程，一个往`Queue`里写数据，一个从`Queue`里读数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process to write: 17560\n",
      "Put A to queue...\n",
      "Process to read: 17563\n",
      "Get A from queue.\n",
      "Put B to queue...\n",
      "Get B from queue.\n",
      "Put C to queue...\n",
      "Get C from queue.\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Queue\n",
    "import os, time, random\n",
    "\n",
    "def write(q):\n",
    "    print('Process to write: %s' % os.getpid())\n",
    "    for value in ['A', 'B', 'C']:\n",
    "        print('Put %s to queue...' % value)\n",
    "        q.put(value)\n",
    "        time.sleep(random.random())\n",
    "def read(q):\n",
    "    print('Process to read: %s' % os.getpid())\n",
    "    while True:\n",
    "        value = q.get(True)\n",
    "        print('Get %s from queue.' % value)\n",
    "if __name__ == '__main__':\n",
    "    q = Queue()\n",
    "    pw = Process(target=write, args=(q,))\n",
    "    pr = Process(target=read, args=(q,))\n",
    "    pw.start()\n",
    "    pr.start()\n",
    "    pw.join()\n",
    "    # 由于read进程是一个死循环，所以这里进行强制停止\n",
    "    pr.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线程\n",
    "\n",
    "多任务可以由多进程完成，也可以由一个进程内的多线程完成。\n",
    "\n",
    "我们前面提到了进程是由若干线程组成的，一个进程至少有一个线程。\n",
    "\n",
    "由于线程是操作系统直接支持的执行单元，因此，高级语言通常都内置多线程的支持，Python也不例外，并且，Python的线程是真正的`Posix Thread`，而不是模拟出来的线程。\n",
    "\n",
    "Python的标准库提供了两个模块：`_thread`和`threading`，`_thread`是低级模块，`threading`是高级模块，对`_thread`进行了封装。绝大多数情况下，我们只需要使用`threading`这个高级模块。\n",
    "\n",
    "启动一个线程就是把一个函数传入并创建`Thread`实例，然后调用`start()`开始执行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread MainThread is running...\n",
      "thread LoopThread is running...\n",
      "thread LoopThread >>> 1\n",
      "thread LoopThread >>> 2\n",
      "thread LoopThread >>> 3\n",
      "thread LoopThread >>> 4\n",
      "thread LoopThread >>> 5\n",
      "thread LoopThread ended.\n",
      "thread MainThread ended\n"
     ]
    }
   ],
   "source": [
    "import time, threading\n",
    "\n",
    "def loop():\n",
    "    print('thread %s is running...' % threading.current_thread().name)\n",
    "    n = 0 \n",
    "    while n < 5:\n",
    "        n = n + 1\n",
    "        print('thread %s >>> %s' % (threading.current_thread().name, n))\n",
    "        time.sleep(1)\n",
    "    print('thread %s ended.' % threading.current_thread().name)\n",
    "\n",
    "print('thread %s is running...' % threading.current_thread().name)\n",
    "t = threading.Thread(target=loop, name='LoopThread')\n",
    "t.start()\n",
    "t.join()\n",
    "print('thread %s ended' % threading.current_thread().name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于任何进程默认就会启动一个线程，我们把该线程称为主线程，主线程又可以启动新的线程，Python的`threading`模块有个`current_thread()`函数，它永远返回当前线程的实例，返回的是一个`Thread`对象，和`threading.Thread()`创建出来的对象一样。主线程实例的名字叫`MainThread`，子线程的名字在创建时指定，我们用`LoopThread`命名子线程。名字仅仅在打印时用来显示，完全没有其他意义，如果不起名字Python就自动给线程命名为`Thread-1`，`Thread-2……`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lock\n",
    "\n",
    "多线程和多进程最大的不同在于，多进程中，同一个变量，各自有一份拷贝存在于每个进程中，互不影响，而多线程中，所有变量都由所有线程共享，所以，任何一个变量都可以被任何一个线程修改，因此，线程之间共享数据最大的危险在于多个线程同时改一个变量，把内容给改乱了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import time, threading\n",
    "\n",
    "# 假定这是你的银行存款:\n",
    "balance = 0\n",
    "lock = threading.Lock()\n",
    "\n",
    "def change_it(n):\n",
    "    # 先存后取，结果应该为0:\n",
    "    global balance\n",
    "    balance = balance + n\n",
    "    balance = balance - n\n",
    "\n",
    "def run_thread(n):\n",
    "    for i in range(100000):\n",
    "        lock.acquire()\n",
    "        try:\n",
    "            change_it(n)\n",
    "        finally:\n",
    "            lock.release()\n",
    "\n",
    "t1 = threading.Thread(target=run_thread, args=(5,))\n",
    "t2 = threading.Thread(target=run_thread, args=(8,))\n",
    "t1.start()\n",
    "t2.start()\n",
    "t1.join()\n",
    "t2.join()\n",
    "print(balance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当多个线程同时执行`lock.acquire()`时，只有一个线程能成功地获取锁，然后继续执行代码，其他线程就继续等待直到获得锁为止。\n",
    "\n",
    "获得锁的线程用完后一定要释放锁，否则那些苦苦等待锁的线程将永远等待下去，成为死线程。所以我们用`try...finally`来确保锁一定会被释放。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python多线程无法利用多核CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading, multiprocessing\n",
    "\n",
    "def loop():\n",
    "    x = 0\n",
    "    while True:\n",
    "        x = x ^ 1\n",
    "\n",
    "for i in range(multiprocessing.cpu_count()):\n",
    "    t = threading.Thread(target=loop)\n",
    "    t.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "启动与CPU核心数量相同的N个线程，在4核CPU上可以监控到CPU占用率仅有102%，也就是仅使用了一核。\n",
    "\n",
    "但是用C、C++或Java来改写相同的死循环，直接可以把全部核心跑满，4核就跑到400%，8核就跑到800%，为什么Python不行呢？\n",
    "\n",
    "因为Python的线程虽然是真正的线程，但解释器执行代码时，有一个GIL锁：Global Interpreter Lock，任何Python线程执行前，必须先获得GIL锁，然后，每执行100条字节码，解释器就自动释放GIL锁，让别的线程有机会执行。这个GIL全局锁实际上把所有线程的执行代码都给上了锁，所以，多线程在Python中只能交替执行，即使100个线程跑在100核CPU上，也只能用到1个核。\n",
    "\n",
    "GIL是Python解释器设计的历史遗留问题，通常我们用的解释器是官方实现的CPython，要真正利用多核，除非重写一个不带GIL的解释器。\n",
    "\n",
    "所以，在Python中，可以使用多线程，但不要指望能有效利用多核。如果一定要通过多线程利用多核，那只能通过C扩展来实现，不过这样就失去了Python简单易用的特点。\n",
    "\n",
    "不过，也不用过于担心，Python虽然不能利用多线程实现多核任务，但可以通过多进程实现多核任务。多个Python进程有各自独立的GIL锁，互不影响。\n",
    "\n",
    "> IO密集型代码(文件处理、网络爬虫等涉及文件读写的操作)，多线程能够有效提升效率(单线程下有IO操作会进行IO等待，造成不必要的时间浪费，而开启多线程能在线程A等待时，自动切换到线程B，可以不浪费CPU的资源，从而能提升程序执行效率)。所以python的多线程对IO密集型代码比较友好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ThreadLocal\n",
    "\n",
    "在多线程环境下，每个线程都有自己的数据。一个线程使用自己的局部变量比使用全局变量好，因为局部变量只有线程自己能看见，不会影响其他线程，而全局变量的修改必须加锁。\n",
    "\n",
    "但是局部变量也有问题，就是在函数调用的时候，传递起来很麻烦："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Student(object):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "def process_student(name):\n",
    "    std = Student(name)\n",
    "    do_task1(std)\n",
    "    do_task2(std)\n",
    "    \n",
    "def do_task1(std):\n",
    "    do_subtask_1(std)\n",
    "    do_subtask_2(std)\n",
    "def do_task2(std):\n",
    "    do_subtask_1(std)\n",
    "    do_subtask_2(std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看到std这个变量在多个函数之间传来传去，又不能使用全局变量，因为每个线程的std是不同的，不能共享。\n",
    "\n",
    "解决方案之一是，用一个全局的`dict`来存放不同线程需要全局共享的变量，`dict`的`key`值就是线程的线程号。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_dict = {}\n",
    "\n",
    "def std_thread(name):\n",
    "    std = Student(name)\n",
    "    global_dict[threading.current_thread()] = std\n",
    "    do_task1()\n",
    "    do_task2()\n",
    "def do_task_1():\n",
    "    std = global_dict[threading.current_thread()]\n",
    "def do_task_2():\n",
    "    std = global_dict[threading.current_thread()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这种方式理论上是可行的，它最大的优点是消除了std对象在每层函数中的传递问题，但是，每个函数获取std的代码有点丑。\n",
    "\n",
    "有没有更简单的方式？\n",
    "\n",
    "`ThreadLocal`应运而生，不用查找`dict`，`ThreadLocal`帮你自动做这件事："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Alice (in Thread-A)\n",
      "Hello, Bob (in Thread-B)\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "local_school = threading.local()\n",
    "\n",
    "def process_student():\n",
    "    std = local_school.student\n",
    "    print('Hello, %s (in %s)' % (std, threading.current_thread().name))\n",
    "def process_thread(name):\n",
    "    local_school.student = name\n",
    "    process_student()\n",
    "\n",
    "t1 = threading.Thread(target=process_thread, args=(\"Alice\",), name = 'Thread-A')\n",
    "t2 = threading.Thread(target=process_thread, args=(\"Bob\",), name = 'Thread-B')\n",
    "t1.start()\n",
    "t2.start()\n",
    "t1.join()\n",
    "t2.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全局变量`local_school`就是一个`ThreadLocal`对象，每个Thread对它都可以读写`student`属性，但互不影响。你可以把`local_school`看成全局变量，但每个属性如`local_school.student`都是线程的局部变量，可以任意读写而互不干扰，也不用管理锁的问题，`ThreadLocal`内部会处理。\n",
    "\n",
    "可以理解为全局变量`local_school`是一个`dict`，不但可以用`local_school.student`，还可以绑定其他变量，如`local_school.teacher`等等。\n",
    "\n",
    "`ThreadLocal`最常用的地方就是为每个线程绑定一个数据库连接，HTTP请求，用户身份信息等，这样一个线程的所有调用到的处理函数都可以非常方便地访问这些资源。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分布式进程\n",
    "\n",
    "Python的multiprocessing模块不但支持多进程，其中managers子模块还支持把多进程分布到多台机器上。一个服务进程可以作为调度者，将任务分布到其他多个进程中，依靠网络通信。由于managers模块封装很好，不必了解网络通信的细节，就可以很容易地编写分布式多进程程序。\n",
    "\n",
    "### Master的代码\n",
    "\n",
    "Master负责用register将一些方向绑定到一个manager上面。这个manager本身对应了一个服务ip+端口。可以绑定一个Queue，也可以绑定一些远程调用函数，比如下面代码中的`hello`。\n",
    "\n",
    "可运行代码位置: [src/task_master.py](./src/task_master.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_master.py\n",
    "\n",
    "import random, time, queue\n",
    "from multiprocessing.managers import BaseManager\n",
    "\n",
    "task_queue = queue.Queue()\n",
    "result_queue = queue.Queue()\n",
    "\n",
    "class QueueManager(BaseManager):\n",
    "    pass\n",
    "\n",
    "def hello(name):\n",
    "    return 'Hello, %s' % name\n",
    "\n",
    "QueueManager.register('get_task_queue', callable=lambda: task_queue)\n",
    "QueueManager.register('get_result_queue', callable=lambda: result_queue)\n",
    "QueueManager.register('hello', callable=hello)\n",
    "\n",
    "manager = QueueManager(address=('', 5000), authkey=b'abc')\n",
    "manager.start()\n",
    "\n",
    "task = manager.get_task_queue()\n",
    "result = manager.get_result_queue()\n",
    "\n",
    "for i in range(10):\n",
    "    n = random.randint(0, 10000)\n",
    "    print('Put task %d' % n)\n",
    "    task.put(n)\n",
    "\n",
    "print('Try get results...')\n",
    "for i in range(10):\n",
    "    r = result.get(timeout=10)\n",
    "    print('Result: %s' % r)\n",
    "\n",
    "manager.shutdown()\n",
    "print('master exit.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "worker里也要像Master一样去注册这些方法，然后通过connect来连接master\n",
    "\n",
    "可运行代码位置: [src/task_worker.py](./src/task_worker.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_worker.py\n",
    "\n",
    "import time, sys, queue\n",
    "from multiprocessing.managers import BaseManager\n",
    "\n",
    "class QueueManager(BaseManager):\n",
    "    pass\n",
    "\n",
    "QueueManager.register('get_task_queue')\n",
    "QueueManager.register('get_result_queue')\n",
    "QueueManager.register('hello')\n",
    "\n",
    "server_addr = '127.0.0.1'\n",
    "print('connect to server %s...' % server_addr)\n",
    "m = QueueManager(address=(server_addr, 5000), authkey=b'abc')\n",
    "m.connect()\n",
    "\n",
    "#hello = m.hello()\n",
    "print(m.hello('master'))\n",
    "\n",
    "task = m.get_task_queue()\n",
    "result = m.get_result_queue()\n",
    "\n",
    "for i in range(10):\n",
    "    try:\n",
    "        n = task.get(timeout=1)\n",
    "        print('run task %d * %d...' % (n, n))\n",
    "        r = '%d * %d = %d' % (n, n, n * n)\n",
    "        time.sleep(1)\n",
    "        result.put(r)\n",
    "    except queue.Empty:\n",
    "        print('task queue is empty')\n",
    "print('worker exit.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
