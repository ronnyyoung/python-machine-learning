{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch　distribution Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 判断当前环境是否支持分布式模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Dist:  True\n"
     ]
    }
   ],
   "source": [
    "print('Support Dist: ', dist.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化进程组\n",
    "\n",
    "我们有多种方式来创建一个进程组\n",
    "\n",
    "`init_method`用于指定master和worker之间的通信的方法：\n",
    "\n",
    "1. 通过一个显式的`tcp://ip:port`的形式\n",
    "2. 通过一个共享文件的方式\n",
    "3. 通过环境变量`MASTER_ADDR`,`MASTER_PORT`来获取，本质上和1是一样的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_process_group(backend,\n",
    "                       init_method=\"env://\",\n",
    "                       timeout=_default_pg_timeout,\n",
    "                       **kwargs):\n",
    "    \"\"\"\n",
    "    Initializes the default distributed process group, and this will also\n",
    "    initialize the distributed package\n",
    "\n",
    "    Arguments:\n",
    "        backend (str or Backend): The backend to use. Depending on\n",
    "            build-time configurations, valid values include ``mpi``, ``gloo``,\n",
    "            and ``nccl``. This field should be given as a lowercase string\n",
    "            (e.g., ``\"gloo\"``), which can also be accessed via\n",
    "            :class:`Backend` attributes (e.g., ``Backend.GLOO``).\n",
    "        init_method (str, optional): URL specifying how to initialize the\n",
    "                                     process group.\n",
    "        world_size (int, optional): Number of processes participating in\n",
    "                                    the job.\n",
    "        rank (int, optional): Rank of the current process.\n",
    "        timeout (timedelta, optional): Timeout for operations executed against\n",
    "            the process group. Default value equals 30 minutes.\n",
    "            This is only applicable for the ``gloo`` backend.\n",
    "        group_name (str, optional, deprecated): Group name.\n",
    "\n",
    "    To enable ``backend == Backend.MPI``, PyTorch needs to built from source\n",
    "    on a system that supports MPI. The same applies to NCCL as well.\n",
    "\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Process Group\n",
    "\n",
    "dist_backend = 'nccl'\n",
    "dist_url = 'tcp://127.0.0.1:23456'\n",
    "rank = 0\n",
    "world_size = 1\n",
    "dist.init_process_group(backend=dist_backend, init_method=dist_url, rank=rank, world_size=world_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 判断是否初始化过"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist is initialized: True\n"
     ]
    }
   ],
   "source": [
    "print('dist is initialized:',dist.is_initialized())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alexnet', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'inception_v3', 'resnet101', 'resnet152', 'resnet18', 'resnet34', 'resnet50', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn']\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))\n",
    "\n",
    "print(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=False).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 如果是单机多卡\n",
    "\n",
    "```python\n",
    "torch.distributed.init_process_group(backend=\"nccl\")\n",
    "model = DistributedDataParallel(model) # device_ids will include all GPU devices be default\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make model DistributedDataParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Args:\n",
    "# -device_ids (list of int or torch.device): CUDA devices (default: all devices)\n",
    "#- output_device (int or torch.device): device location of output (default: device_ids[0])\n",
    "\n",
    "# model = torch.nn.parallel.DistributedDataParallel(model, device_ids=dp_device_ids, output_device=local_rank)\n",
    "model = torch.nn.parallel.DistributedDataParallel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_lr = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), starting_lr, momentum=0.9, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xe4\\xb8\\xa5'\n",
      "b'\\xff\\xfe\\x00\\x00%N\\x00\\x00'\n"
     ]
    }
   ],
   "source": [
    "s = '严'\n",
    "print(s.encode('utf-8'))\n",
    "print(s.encode('utf-32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
